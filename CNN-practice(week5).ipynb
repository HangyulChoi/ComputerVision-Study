{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"week5_practice.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNn0Os0uHASC2nnTygXPYzi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"RWoaXlhmHkYx"},"source":["import tensorflow as tf\n","(mnist_images, mnist_labels),_ = tf.keras.datasets.mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNb3uEMmHAVy"},"source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# 정규화 및 타입 변경\n","mnist_images = tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32)\n","mnist_labels = tf.cast(mnist_labels, tf.int64)\n","\n","\n","X_train = mnist_images[:50000, :, :, :]\n","y_train = mnist_labels[:50000]\n","\n","X_test = mnist_images[55000:, :, :, :]\n","y_test = mnist_labels[55000:]\n","\n","X_valid = mnist_images[50000:55000, :, :, :]\n","y_valid = mnist_labels[50000:55000]\n","\n","\n","# scaler = StandardScaler()\n","# scaler.fit(X_train)\n","\n","# X_mean = scaler.mean_\n","# X_std = scaler.scale_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZHp6NBFG2Q1"},"source":["def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n","    housing_dir = os.path.join(\"datasets\", \"housing\")\n","    os.makedirs(housing_dir, exist_ok=True)\n","    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n","\n","    filepaths = []\n","    m = len(data)\n","    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n","        part_csv = path_format.format(name_prefix, file_idx)\n","        filepaths.append(part_csv)\n","        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n","            if header is not None:\n","                f.write(header)\n","                f.write(\"\\n\")\n","            for row_idx in row_indices:\n","                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n","                f.write(\"\\n\")\n","    return filepaths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgqfKlOYIrSw"},"source":["# X_train = tf.reshape(X_train, (-1, 784))\n","X_valid = tf.reshape(X_valid, (-1, 784))\n","X_test = tf.reshape(X_test, (-1, 784))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szz4c6L8J2DX","executionInfo":{"status":"ok","timestamp":1617108163112,"user_tz":-540,"elapsed":369,"user":{"displayName":"Hangyul Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVf-BMxmuhNR5NmPoed-bik8Hh90LtEhpzPLEzmQ=s64","userId":"11991495386065137896"}},"outputId":"871317ae-b4a4-45bc-b9ca-dd82d8395c83"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([50000, 784])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"OtnyEUDoG6at"},"source":["train_data = np.c_[X_train, y_train]\n","valid_data = np.c_[X_valid, y_valid]\n","test_data = np.c_[X_test, y_test]\n","header_cols = \n","header = \",\".join(header_cols)\n","\n","train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20) # 20개 csv 파일로 나눠주고, TextLineDataset 5개를 순환하면서 한 줄씩 넣고\n","valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n","test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bufjIbBpKyDl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEk0iSCSIKnz","executionInfo":{"status":"ok","timestamp":1617107783386,"user_tz":-540,"elapsed":1065,"user":{"displayName":"Hangyul Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVf-BMxmuhNR5NmPoed-bik8Hh90LtEhpzPLEzmQ=s64","userId":"11991495386065137896"}},"outputId":"4c84494e-b963-48e0-bc45-04ac06fc435d"},"source":["# X_train.shape\n","y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([50000])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"haE8UBJtD1qd"},"source":["# 적재, 셔플링\n","\n","def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n","                       n_read_threads=None, shuffle_buffer_size=10000,\n","                       n_parse_threads=5, batch_size=32):\n","    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n","    dataset = dataset.interleave(\n","        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n","        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n","    dataset = dataset.shuffle(shuffle_buffer_size)\n","    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n","    dataset = dataset.batch(batch_size)\n","    return dataset.prefetch(1)  # 학습 성능에 매우 중요!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"KTjngch9EUC2","executionInfo":{"status":"error","timestamp":1617107098571,"user_tz":-540,"elapsed":591,"user":{"displayName":"Hangyul Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVf-BMxmuhNR5NmPoed-bik8Hh90LtEhpzPLEzmQ=s64","userId":"11991495386065137896"}},"outputId":"e74597dc-d102-4991-836f-7bb743296337"},"source":["train_set = csv_reader_dataset(train_filepaths, repeat=None)\n","valid_set = csv_reader_dataset(valid_filepaths)\n","test_set = csv_reader_dataset(test_filepaths) # 각 데이터셋 만들어주고 이전처럼 적용"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3f09a221a3bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_reader_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_filepaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_reader_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_filepaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_reader_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_filepaths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 각 데이터셋 만들어주고 이전처럼 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_filepaths' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EK_5PdH7Cqfy","executionInfo":{"status":"ok","timestamp":1617106323153,"user_tz":-540,"elapsed":556,"user":{"displayName":"Hangyul Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVf-BMxmuhNR5NmPoed-bik8Hh90LtEhpzPLEzmQ=s64","userId":"11991495386065137896"}},"outputId":"39f04383-cb9d-41c0-aaa9-7e607b7df0a1"},"source":["keras.backend.clear_session()\n","\n","# CNN 모델 라이브러리\n","from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n","from keras.models import Sequential\n","from keras.utils import to_categorical\n","\n","# reduceLR 콜백함수\n","from keras.callbacks import ReduceLROnPlateau\n","\n","reduceLR = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.1)\n","\n","# Earlystopping 콜백함수\n","from keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(monitor='val_loss', verbose=1, patience=15)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size =(3,3), input_shape = (28, 28, 1), activation='relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size = 2))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation = 'softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9216)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                589888    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 609,354\n","Trainable params: 609,354\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SVmqSJ1VC-uX"},"source":["model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VlqiuyzBEBKk"},"source":["history = model.fit(train_images, train_labels,\n","          batch_size=128,\n","          epochs=30,\n","          verbose=1, \n","          validation_data=(valid_images, valid_labels),\n","          callbacks=[es, reduceLR])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SR7xdn_ECZa"},"source":["fig, loss_ax = plt.subplots(figsize = (8, 5))\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(history.history['loss'], 'y', label='train loss')\n","loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n","\n","acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n","acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuracy')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}